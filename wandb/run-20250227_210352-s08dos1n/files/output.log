2025-02-27:21:03:53,562 INFO     [__main__.py:279] Verbosity set to INFO
2025-02-27:21:03:59,150 INFO     [__main__.py:376] Selected Tasks: ['openbookqa']
2025-02-27:21:03:59,155 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-27:21:03:59,156 INFO     [evaluator.py:201] Initializing huggingface model, with arguments: {'pretrained': 'nlptown/bert-base-multilingual-uncased-sentiment', 'max_length': 512, 'truncation': True, 'cache_dir': 'hf_cache'}
2025-02-27:21:03:59,220 INFO     [huggingface.py:132] Using device 'cuda'
C:\Users\msocz\AppData\Local\Programs\Python\Python311\Lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\msocz\workbench\oliveai\trend-evalute\hf_cache\hub\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
2025-02-27:21:04:01,112 INFO     [huggingface.py:369] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
C:\Users\msocz\AppData\Local\Programs\Python\Python311\Lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\msocz\workbench\oliveai\trend-evalute\hf_cache\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of BertLMHeadModel were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading readme: 100%|██████████| 9.06k/9.06k [00:00<00:00, 1.09MB/s]
Downloading data: 100%|██████████| 496k/496k [00:00<00:00, 1.24MB/s]
Downloading data: 100%|██████████| 58.2k/58.2k [00:00<00:00, 216kB/s]
Downloading data: 100%|██████████| 55.5k/55.5k [00:00<00:00, 212kB/s]
Generating train split: 100%|██████████| 4957/4957 [00:00<00:00, 365809.78 examples/s]
Generating validation split: 100%|██████████| 500/500 [00:00<00:00, 985040.86 examples/s]
Generating test split: 100%|██████████| 500/500 [00:00<00:00, 525075.61 examples/s]
2025-02-27:21:06:47,347 WARNING  [evaluator.py:270] Overwriting default num_fewshot of openbookqa from None to 5
2025-02-27:21:06:47,351 INFO     [task.py:415] Building contexts for openbookqa on rank 0...
100%|██████████| 500/500 [00:01<00:00, 298.03it/s]
2025-02-27:21:06:49,049 INFO     [evaluator.py:496] Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/2000 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
Running loglikelihood requests: 100%|██████████| 2000/2000 [00:04<00:00, 410.58it/s]
2025-02-27:21:06:57,110 INFO     [evaluation_tracker.py:206] Saving results aggregated
huggingface (pretrained=nlptown/bert-base-multilingual-uncased-sentiment,max_length=512,truncation=True,cache_dir=hf_cache), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 8
|  Tasks   |Version|Filter|n-shot| Metric |   |Value|   |Stderr|
|----------|------:|------|-----:|--------|---|----:|---|-----:|
|openbookqa|      1|none  |     5|acc     |↑  |0.158|±  |0.0163|
|          |       |none  |     5|acc_norm|↑  |0.258|±  |0.0196|
